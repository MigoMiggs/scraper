{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "29a1d54a-c807-4af9-b2f2-abb81e88d702",
   "metadata": {},
   "source": [
    "# IBTS Production Grade RAG\n",
    "This notebooks shows step by step how we get the right answers from the knowledge base. The notebook is meant to be educational showiong a few different possibilities that one can take to tune the system.\n",
    "\n",
    "## Step 1 - Do all the setup, imports,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9a428564-d04d-4bad-ba0f-1930c85e1acf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import openai\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "import os\n",
    "\n",
    "from langchain.vectorstores import Chroma\n",
    "from langchain.load import dumps, loads\n",
    "from langchain import hub\n",
    "from langchain.embeddings import HuggingFaceEmbeddings, OpenAIEmbeddings\n",
    "from langchain.prompts.chat import (\n",
    "    SystemMessagePromptTemplate, \n",
    "    HumanMessagePromptTemplate, \n",
    "    ChatPromptTemplate\n",
    ")\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.chains import (RetrievalQA, \n",
    "    RetrievalQAWithSourcesChain\n",
    ")\n",
    "\n",
    "from langchain.chat_models import ChatOpenAI, AzureChatOpenAI\n",
    "from langchain.chains.summarize import load_summarize_chain\n",
    "from langchain.docstore.document import Document\n",
    "from langchain.retrievers.multi_query import MultiQueryRetriever\n",
    "from langchain.schema.output_parser import StrOutputParser\n",
    "\n",
    "_ = load_dotenv(find_dotenv()) # read local .env file\n",
    "#openai.api_key = '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'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "698705a6-ea27-4542-9a0b-d0a6f061bf6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Embeddings\n",
    "embeddings = OpenAIEmbeddings()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8a8dcdea-e023-4035-915c-31acb6552765",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_gptmodel(use_azure, model_name):\n",
    "\n",
    "    llm_model = None\n",
    "    if use_azure:\n",
    "        llm_model = AzureChatOpenAI(\n",
    "            openai_api_base=\"https://sondertest.openai.azure.com/\",\n",
    "            openai_api_version=\"2023-07-01-preview\",\n",
    "            deployment_name=\"dev-gpt-35-turbo-16k\",\n",
    "            openai_api_key=os.getenv(\"OPENAI_API_AZURE_KEY\"),\n",
    "            openai_api_type=\"azure\",\n",
    "            temperature=0 \n",
    "            )\n",
    "    else: \n",
    "        llm_model = ChatOpenAI(model_name=model_name, temperature=0)\n",
    "\n",
    "    return llm_model\n",
    "\n",
    "\n",
    "# Instantiate the model object\n",
    "llm_model = \"gpt-3.5-turbo-16k\"\n",
    "llm = get_gptmodel(True, llm_model)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14216cf0-499c-4597-bfc8-c926c2bcda78",
   "metadata": {},
   "source": [
    "## Step 2 Load the DB and setup the plain vanilla retriever\n",
    "The plain vanilla retriver will just fetch the most similar chunks from the embedded dB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "37e51a28-5a72-4c19-a4f6-160b47cfd97d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the chroma DB\n",
    "persist_directory = '../chroma_clean_ada/'\n",
    "vectordb = Chroma(persist_directory=persist_directory, embedding_function=embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2226412c-bca9-4864-ad8e-b72be3cac1d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total chunks: 120547\n"
     ]
    }
   ],
   "source": [
    "# Display the number of document chunks in the DB\n",
    "print(f\"Total chunks: {vectordb._collection.count()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "308ee762-bb21-4b86-a8de-2d63abb9d61a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make siure that our retriever gets back 6 results\n",
    "retriever = vectordb.as_retriever(search_type=\"similarity\", search_kwargs={\"k\":7})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b7a3df9-9e0a-4dac-a41d-1304f4a1d05b",
   "metadata": {},
   "source": [
    "## Step 3 - Run a query with simple retriever"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56a5f970-40c8-4c88-8b52-cd6c3427d05b",
   "metadata": {},
   "source": [
    "Set up the simple QA chanin with just the plain vanilla retriver to see what we get out of the bo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2c65d909-0255-4e31-a96b-fab2a1e4f998",
   "metadata": {},
   "outputs": [],
   "source": [
    "qa_chain = RetrievalQA.from_chain_type(\n",
    "    llm,\n",
    "    retriever=retriever\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f5b2ca70-c1cd-4ed1-b6ed-c983328edc69",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The key aspects of the Orlando budget guide include:\n",
      "\n",
      "1) Policy Guide: The budget serves as a policy document that informs the reader about the municipality and its policies. It includes organization-wide financial and programmatic policies and goals that address long-term concerns and issues, as well as short-term financial and operational policies that guide the development of the annual budget. The department budget sections provide mission statements, major accomplishments, future outlook (goals), and performance indicators for each department.\n",
      "\n",
      "2) Financial Plan: The budget details the costs associated with providing municipal services and how these services will be funded. It includes a summary and detailed description of all revenues and expenditures. The budget serves as a financial plan for the city, outlining the financial resources available and how they will be allocated to meet the needs of the community.\n",
      "\n",
      "3) Decision-Making: The Mayor and City Council are responsible for setting the guidelines and developing a balanced budget. They make decisions about where, how, and why taxpayer dollars are spent, ensuring that spending is done responsibly and in the best interest of the city. The budget reflects the choices and decisions made by the city's elected leaders.\n",
      "\n",
      "4) Economic Climate: The budget takes into account the economic climate and any challenges or changes in revenue. It addresses the need to live within the city's means while still providing superior services to the community. The budget document may highlight the city's financial stability and its ability to navigate through economic downturns.\n",
      "\n",
      "Overall, the budget guide provides a comprehensive overview of the city's policies, financial plan, decision-making process, and response to economic conditions.\n"
     ]
    }
   ],
   "source": [
    "query  = \"what are the key aspects of the orlando budget guide?\"\n",
    "result = qa_chain({\"query\": query})\n",
    "print(result[\"result\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87efef95-1419-4680-b9a7-3919b35b2a66",
   "metadata": {},
   "source": [
    "## Step 4 - Meta prompt utilizing questions form the City Of Orlando Assessment \n",
    "\n",
    "Here we are going to put the multiple question guidance in the system prompt and will instruct GPT how to handle them and the answers. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "116a7d0c-3a1d-4557-a636-64c7033ccce5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#### System Prompt Construction\n",
    "\n",
    "system_template = \"\"\"\" \\\n",
    "Instructions:\n",
    "* You are an evaluator that knows about Natural Disaster Recovery. \\\n",
    "* User will provider a multiple choice question and the possible answers below. \\\n",
    "* You will pick the best answer based on the included pieces of context. The questions \\\n",
    "will always go from 1 - 6, the 6th answer is always \"I don't know.\" \n",
    "* Answers 1 - 5 will go from low to high, from the perspecive of how good \\\n",
    "the adherence is to the provided question. \n",
    "* These questions and answers are used for Natural Disaster Readiness. \\\n",
    "* The Community Resilience Assessment Framework and Tools (CRAFT) \\\n",
    "* Equitable Climate Resilience (ECR) platform is a resource for cities to assess and strengthen their resilience - \\\n",
    "the ability to to mitigate, respond to, and recover from crises. Also, after the answer, you will explain how you got to the answer, \\ \n",
    "referrring to the pieces of context that gave you the answer. \\n\\\n",
    "-------------------- \\n\\\n",
    "Context:\n",
    "{context}\n",
    "\"\"\"\n",
    "system_message_prompt = SystemMessagePromptTemplate.from_template(system_template)\n",
    "\n",
    "human_template=\"\"\" {question} \"\"\"\n",
    "human_message_prompt = HumanMessagePromptTemplate.from_template(human_template)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "fd719370-7102-40f0-ae93-a92a7010dc07",
   "metadata": {},
   "outputs": [],
   "source": [
    "chat_prompt = ChatPromptTemplate.from_messages([system_message_prompt, human_message_prompt])\n",
    "ChatPromptTemplate.input_variables=[\"question\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "fa65bab9-4440-4a18-b706-2696fe6697eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "qa_chain = RetrievalQA.from_chain_type(\n",
    "    llm,\n",
    "    retriever=retriever,\n",
    "    chain_type_kwargs={\n",
    "        \"prompt\": chat_prompt\n",
    "    }, \n",
    "    return_source_documents=True\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "bc9a47da-0ad7-470a-996e-81bae523c521",
   "metadata": {},
   "outputs": [],
   "source": [
    "#### User Prompt\n",
    "#### Question 1A from the Orlando-PreAssessment\n",
    "\n",
    "query = \"To what extent is the relationship between climate hazards and \\\n",
    "social vulnerability/inequity understood among city leaders and staff? \\n\\n\"\n",
    "\n",
    "answers = \"\\\n",
    "Possible Answers: \\n\\\n",
    "1 (Low) The relationship between climate hazards and social inequity has not been explored by staff or elected officials \\n\\\n",
    "2 (LowMid) \\n\\\n",
    "3 (Medium) The relationship between climate hazards and social inequity is familiar to select city staff or elected \\n\\\n",
    "officials \\n\\\n",
    "4 (MidHigh) \\n\\\n",
    "5 (High) City staff and elected officials are well-versed in the concepts and taxonomy of the relationship between climate hazards and social inequity \\n\\\n",
    "6 I dont know \\n \"\n",
    "\n",
    "query += answers\n",
    "\n",
    "#human_template=\"\"\" {question} \"\"\"\n",
    "#human_message_prompt = HumanMessagePromptTemplate.from_template(human_template)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d0bd87f4-cff2-4d98-a205-afe633c51e0d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "To what extent is the relationship between climate hazards and social vulnerability/inequity understood among city leaders and staff? \n",
      "\n",
      "Possible Answers: \n",
      "1 (Low) The relationship between climate hazards and social inequity has not been explored by staff or elected officials \n",
      "2 (LowMid) \n",
      "3 (Medium) The relationship between climate hazards and social inequity is familiar to select city staff or elected \n",
      "officials \n",
      "4 (MidHigh) \n",
      "5 (High) City staff and elected officials are well-versed in the concepts and taxonomy of the relationship between climate hazards and social inequity \n",
      "6 I dont know \n",
      " \n"
     ]
    }
   ],
   "source": [
    "print(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "21a0a291-76be-404b-a155-4d7ebe9d2cc8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer: 3 (Medium) The relationship between climate hazards and social inequity is familiar to select city staff or elected officials.\n",
      "\n",
      "Explanation: Based on the provided context, it is mentioned that in the City's Climate Vulnerability Assessment, completed in 2017, the relationship between hazards and risks from the changing climate, as well as demographics such as children, the ill, and the elderly, is investigated. This suggests that at least some city staff or elected officials have knowledge and understanding of the relationship between climate hazards and social vulnerability/inequity. However, it is not stated that all city staff or elected officials are well-versed in these concepts, indicating a medium level of understanding among them.\n"
     ]
    }
   ],
   "source": [
    "#query  = \"what are the key aspects of the orlando budget guide?\"\n",
    "result = qa_chain({\"query\": query})\n",
    "print(result[\"result\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "534d51bc-9fcc-462a-9594-18162a1faf23",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(page_content='In the City’s Climate Vulnerability Assessment, completed in 2017, the relationship between hazards and risks from the changing climate, such as the impact of extreme heat on key sectors of employment in the area, including outdoor jobs in tourism, hospitality, landscaping, and public safety, as well as demographics, such as children, the ill, and the elderly, is investigated. Further exploration regarding the impact of climate migration due to both Orlando’s geographic location inland in Central Florida, as well as our ethnically-diverse population, is currently being conducted as part of the development of the City’s first-ever resilience plan.\\xa0 SPOTLIGHT ON WELL-BEING:', metadata={'source': './scraped/www_orlando_gov-Our-Government-Departments-Offices-Executive-Offices-CAO-Sustainability-Resilience-Orlando-Voluntary-Local-Review.txt'}),\n",
       " Document(page_content='impacts caused by these hazards. Orlando is centrally located in Florida, so the City is most susceptible \\r\\nto flooding, hurricanes, severe thunderstorms, lightning, heat waves, wildfires, extremely cold weather, \\r\\ntornadoes, and drought. The City’s Office of Emergency Management provides guides and a citizen \\r\\ninformation line to Citizens regarding these primary hazards.\\r\\nDescribe the vulnerability to these risks of housing occupied by low- and moderate-income \\r\\nhouseholds based on an analysis of data, findings, and methods.\\r\\nOutlined in the Needs Assessment section of this Plan, the primary housing issue experienced by low\\ufffeand-moderate income households within the City is being cost-burdened or severely cost\\ufffeburdened. Spending a significant amount of income on housing leaves less money to prepare, respond, \\r\\nand recover from emergency situations. According to a Supplemental Research Bulletin by the', metadata={'page': 114, 'source': './scraped/2021-2025-consolidated-plan-final-with-attachments.pdf'}),\n",
       " Document(page_content='• Work with partners in academia, public and private sector to conduct Orlando specific asset \\r\\no Extreme heat: Electricity demand projections, required additional capacity and cost \\r\\nimpacts on energy affordability for Orlando’s Low to Moderate Income households. \\r\\no Sea level rise and hurricanes: Mass migration (long and short-term) into Orlando, \\r\\nknown as \"climate refugees,” and impacts on housing demand, affordability and \\r\\nother infrastructure demands (e.g. water supply and treatment). \\r\\no Inland flooding: Road impact projections under extreme precipitation events \\r\\nrestricting travel of residents and visitors participating in employment, education, \\r\\n• Following a similar stakeholder engagement process, develop climate adaptation goals, \\r\\ntargets, and strategies as they pertain to these hazards, vulnerabilities, and opportunities to \\r\\naccelerate growth in Orlando’s climate adaptive capacity.', metadata={'page': 470, 'source': './scraped/final_futurereadycityplan-appendix.pdf'}),\n",
       " Document(page_content='and its predictors. Work to date includes data collected through community engagement, an identification of key \\r\\nperformance indicators according to both empirical research, as well as national and international best practices, \\r\\nand grant-funded partnerships, including the expansion of air quality monitoring across Orange County in \\r\\ncollaboration with the University of Central Florida.\\r\\nIn the City’s Climate Vulnerability Assessment, completed in 2017, the relationship between hazards and risks \\r\\nfrom the changing climate, such as the impact of extreme heat on key sectors of employment in the area, \\r\\nincluding outdoor jobs in tourism, hospitality, landscaping, and public safety, as well as demographics, such as \\r\\nchildren, the ill, and the elderly, is investigated. Further exploration regarding the impact of climate migration due \\r\\nto both Orlando’s geographic location inland in Central Florida, as well as our ethnically-diverse population, is', metadata={'page': 8, 'source': './scraped/21_exo_orlandovoluntarylocalreviewreport_091621.pdf'}),\n",
       " Document(page_content='the capacity of a system to undergo disturbance and maintain its functions and controls. The city must be prepared for disturbances such as hurricanes, possible fuel shortages, drought, extreme rain events, electricity outages, terrorist attacks as well as urban heat island effect. The sections in this report go into more detail as to how the city is working to become more resilient. Accomplishment highlights Areas that need more work Goal 1: Greenhouse Gas Neutral for Municipal Operations by 2030 Why green house gas emissions are important The city can provide regional leadership to reduce greenhouse gasses (GHGs) in a manner that creates greater numbers of clean tech jobs here in Central Florida and reduces the city’s $26 million annual energy costs. As fossil fuel usage has increased over the last 200 years, the concentration of GHGs, such as carbon dioxide, in the atmosphere has increased at a quicker rate than natural systems can absorb them. Trapped GHGs gradually increase the', metadata={'source': './scraped/www_orlando_gov-Our-Government-Departments-Offices-Executive-Offices-CAO-Sustainability-Resilience-2017-Municipal-Operations-Sustainability-Plan.txt'}),\n",
       " Document(page_content='MA-65 Hazard Mitigation - 91.210(a)(5), 91.310(a)(3)\\r\\nDescribe the jurisdiction’s increased natural hazard risks associated with climate change.\\r\\nAccording to the Florida Division of Emergency Management, typical natural hazards that impact Florida \\r\\ninclude drought, floods, wildfire, extremely cold weather, hurricanes, lightning, severe thunderstorms, \\r\\nheat waves, tornadoes, and marine hazards such as rip currents and waterspouts. According to the \\r\\nFederal Emergency Management Administration (FEMA), climate change poses challenges exacerbating \\r\\nnatural disasters, one major issue caused by climate change that will have a direct impact on the natural \\r\\nhazards seen in Florida is sea level rise. In addition to the impacts associated with sea-level rise, many of \\r\\nthe hazards are likely to intensify and increase in frequency with the rising temperatures.\\r\\nKnowing what to prepare for at a local level is critical in better insulating the City from the impending', metadata={'page': 114, 'source': './scraped/2021-2025-consolidated-plan-final-with-attachments.pdf'})]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "docs = result.get(\"source_documents\", [])\n",
    "docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a262642c-6917-4772-a189-8f6f7f170172",
   "metadata": {},
   "outputs": [],
   "source": [
    "##### Run another question to see the results  ######\n",
    "#### Question 5d from the Orlando-PreAssessment\n",
    "\n",
    "query = \"Have potential barriers to the participation of vulnerable populations in \\\n",
    "the planning and implementation process been identified for the City Of Orlando? \\n\\n\"\n",
    "\n",
    "answers = \"Possible answers: \\n\\\n",
    "1 (Low) Potential barriers have not been studied or identified \\n\\\n",
    "2 (LowMid) \\n\\\n",
    "3 (Medium) Potential barriers have been identified, and plans to reduce barriers to participation are underway \\n\\\n",
    "4 (MidHigh) \\n\\\n",
    "5 (High) Barriers have been identified and the city has taken corrective action to reduce these barriers \\\n",
    "\"\n",
    "\n",
    "query += answers\n",
    "\n",
    "print(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa3bfc26-8891-4996-851d-556c437441c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "result = qa_chain({\"query\": query})\n",
    "print(result[\"result\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddb2eca9-9e12-4173-81ce-9804abad1cea",
   "metadata": {},
   "outputs": [],
   "source": [
    "docs = result.get(\"source_documents\", [])\n",
    "docs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a7796d7-489c-4551-8e82-16543b2bfb20",
   "metadata": {},
   "source": [
    "## Step 5 - Compare results with using a MultiQueryRetriever\n",
    "\n",
    "We are going to try to get even better results using a multi query retriiver, it may not affect the answer from multiple choice, but it will affect the explanation for the answer below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5f27656-9ebd-4a17-a8bb-97bb4da7e3b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "retriever = MultiQueryRetriever.from_llm(\n",
    "    retriever=vectordb.as_retriever(search_kwargs={\"k\":6}), llm=llm\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e56d3d2b-338f-4b06-8086-cbe14e89cb44",
   "metadata": {},
   "outputs": [],
   "source": [
    "###### Use the same query as above\n",
    "qa_chain = RetrievalQA.from_chain_type(\n",
    "    llm,\n",
    "    retriever=retriever,\n",
    "    chain_type_kwargs={\n",
    "        \"prompt\": chat_prompt\n",
    "    },\n",
    "    return_source_documents=True\n",
    ")\n",
    "\n",
    "result = qa_chain({\"query\": query})\n",
    "print(result[\"result\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e98faaa-d9da-49b4-b7c6-e2b865a06b59",
   "metadata": {},
   "outputs": [],
   "source": [
    "docs = result.get(\"source_documents\", [])\n",
    "docs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc915fb5-2278-4eef-992e-cccb9344f1dc",
   "metadata": {},
   "source": [
    "## Step 6 - Go next level with Rank Fusion\n",
    "\n",
    "This is something taken from this repo originally: https://github.com/langchain-ai/langchain/blob/master/cookbook/rag_fusion.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "375556bf-e125-474a-a98a-60768a6deb0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = hub.pull('langchain-ai/rag-fusion-query-generation')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87e235d7-b71e-42ac-9a5a-24da3b77b775",
   "metadata": {},
   "outputs": [],
   "source": [
    "# prompt = ChatPromptTemplate.from_messages([\n",
    "#     (\"system\", \"You are a helpful assistant that generates multiple search queries based on a single input query.\"),\n",
    "#     (\"user\", \"Generate multiple search queries related to: {original_query}\"),\n",
    "#     (\"user\", \"OUTPUT (4 queries):\")\n",
    "# ])\n",
    "generate_queries = prompt | ChatOpenAI(temperature=0) | StrOutputParser() | (lambda x: x.split(\"\\n\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c6072ba-d640-418b-93f9-6c929f29e0eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def reciprocal_rank_fusion(results: list[list], k=60):\n",
    "    fused_scores = {}\n",
    "    for docs in results:\n",
    "        # Assumes the docs are returned in sorted order of relevance\n",
    "        for rank, doc in enumerate(docs):\n",
    "            doc_str = dumps(doc)\n",
    "            if doc_str not in fused_scores:\n",
    "                fused_scores[doc_str] = 0\n",
    "            previous_score = fused_scores[doc_str]\n",
    "            fused_scores[doc_str] += 1 / (rank + k)\n",
    "            \n",
    "    reranked_results = [(loads(doc), score) for doc, score in sorted(fused_scores.items(), key=lambda x: x[1], reverse=True)]\n",
    "    return reranked_results "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7533d55-6120-4a40-838c-ef98112611f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "chain = generate_queries | retriever.map() | reciprocal_rank_fusion\n",
    "docs = chain.invoke({\"original_query\": query})\n",
    "\n",
    "doc_list = []\n",
    "for d in docs:\n",
    "    for dd in d:\n",
    "        if hasattr(dd, 'page_content'):\n",
    "            doc_list.append(dd)\n",
    "     \n",
    "\n",
    "len(doc_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e112bd7-3e94-45d7-aa47-9919793d4a34",
   "metadata": {},
   "outputs": [],
   "source": [
    "rank_fusion_db = Chroma.from_documents(doc_list, embeddings)\n",
    "retriever=rank_fusion_db.as_retriever(search_kwargs={\"k\":10})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c957301-f882-4d45-8b1a-5788bd7917cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "###### Use the same query as above\n",
    "qa_chain = RetrievalQA.from_chain_type(\n",
    "    llm,\n",
    "    retriever=retriever,\n",
    "    chain_type_kwargs={\n",
    "        \"prompt\": chat_prompt\n",
    "    }, \n",
    "    return_source_documents=True\n",
    ")\n",
    "\n",
    "result = qa_chain({\"query\": query})\n",
    "print(result[\"result\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f67ea232-0b4b-4f08-b5a5-ccba919dd638",
   "metadata": {},
   "outputs": [],
   "source": [
    "##### Run another question to see the results  ######\n",
    "#### Question 5a from the Orlando-PreAssessment\n",
    "\n",
    "query = \"To what extent are ECR-related priorities/projects coordinated with regional \\\n",
    "jurisdictions (e.g., city, county, state, districts, etc.)? \\n\"\n",
    "\n",
    "answers = \"Possible answers: \\n\\\n",
    "1 (Low)  The city does not coordinate with regional jurisdictions \\n\\\n",
    "2 (LowMid) \\n\\\n",
    "3 (Medium) The city informally coordinates with select regional jurisdictions \\n\\\n",
    "4 (MidHigh) \\n\\\n",
    "5 (High) The city has an established network and forum to coordinate with regional jurisdictions \\\n",
    "\"\n",
    "\n",
    "query += answers\n",
    "\n",
    "print(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91c21887-6c1b-49d0-914b-02d80c973bc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "chain = generate_queries | retriever.map() | reciprocal_rank_fusion\n",
    "docs = chain.invoke({\"original_query\": query})\n",
    "\n",
    "doc_list = []\n",
    "for d in docs:\n",
    "    for dd in d:\n",
    "        if hasattr(dd, 'page_content'):\n",
    "            doc_list.append(dd)\n",
    "     \n",
    "\n",
    "len(doc_list)\n",
    "\n",
    "rank_fusion_db = Chroma.from_documents(doc_list, embeddings)\n",
    "retriever=rank_fusion_db.as_retriever(search_kwargs={\"k\":10})\n",
    "\n",
    "qa_chain = RetrievalQA.from_chain_type(\n",
    "    llm,\n",
    "    retriever=retriever,\n",
    "    chain_type_kwargs={\n",
    "        \"prompt\": chat_prompt\n",
    "    }, \n",
    "    return_source_documents=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "526d0063-96d2-4d4e-9fe6-176f2ae134b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "result = qa_chain({\"query\": query})\n",
    "print(result[\"result\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2dc7415-92f4-429a-ac25-bdebf06af15a",
   "metadata": {},
   "source": [
    "## More Questions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3601d31c-df08-448e-847e-23acfc694b50",
   "metadata": {},
   "outputs": [],
   "source": [
    "##### Run another question to see the results  ######\n",
    "#### Question 5b from the Orlando-PreAssessment\n",
    "\n",
    "query = \"Is there an established network of trusted agents to assist the city with reaching historically \\\n",
    "marginalized and/or vulnerable populations?? \\n\"\n",
    "\n",
    "answers = \"Possible answers: \\n\\\n",
    "1 (Low)  The city has not identified or utilized potential trusted agents to assist with community engagement activities \\n\\\n",
    "2 (LowMid) \\n\\\n",
    "3 (Medium) The city has identified and engaged with limited trusted agents to assist with community engagement activities \\n\\\n",
    "4 (MidHigh) \\n\\\n",
    "5 (High) The city has identified and utilized trusted agents to assist with all community engagement activities \\\n",
    "\"\n",
    "\n",
    "query += answers\n",
    "\n",
    "print(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "513ed9b1-4ee6-4e62-8e5c-aa9ef2bb0624",
   "metadata": {},
   "outputs": [],
   "source": [
    "result = qa_chain({\"query\": query})\n",
    "print(result[\"result\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09cb161f-0496-42ca-ab80-1d112ad23f43",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
