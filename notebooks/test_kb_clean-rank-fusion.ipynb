{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6a644fc-9ef1-4616-88dd-7fc3ba2d6a0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.vectorstores import Chroma\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "from langchain.embeddings import HuggingFaceEmbeddings, OpenAIEmbeddings\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "import openai\n",
    "from langchain.chains import RetrievalQA\n",
    "from langchain.retrievers.multi_query import MultiQueryRetriever\n",
    "import os\n",
    "from langchain.prompts.chat import (\n",
    "    ChatPromptTemplate,\n",
    "    HumanMessagePromptTemplate,\n",
    ")\n",
    "from langchain.prompts import PromptTemplate\n",
    "\n",
    "_ = load_dotenv(find_dotenv()) # read local .env file\n",
    "print(os.environ['LANGCHAIN_API_KEY'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3da21d7f-09d2-4f27-b4f7-bf4a240af39f",
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings_model_name = \"sentence-transformers/all-MiniLM-L6-v2\"\n",
    "embeddings = OpenAIEmbeddings()\n",
    "\n",
    "#embeddings_model_name = 'thenlper/gte-base'\n",
    "#embeddings = HuggingFaceEmbeddings(model_name=embeddings_model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d43f884c-1fbc-4d25-ae34-6617834e261e",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm_model = \"gpt-3.5-turbo-16k\"\n",
    "llm = ChatOpenAI(model_name=llm_model, temperature=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "168e7809-a575-45b9-8df4-50d9a9e43367",
   "metadata": {},
   "outputs": [],
   "source": [
    "persist_directory = '../chroma_clean_ada/'\n",
    "vectordb = Chroma(persist_directory=persist_directory, embedding_function=embeddings)\n",
    "\n",
    "print(vectordb._collection.count())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25182d1b-2d8f-4e69-b36c-1e63d595d1f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#retriever = vectordb.as_retriever(search_type=\"similarity\", search_kwargs={\"k\":5})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05dd4da9-4cfa-4487-8fc9-1b85dc1530c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "retriever = MultiQueryRetriever.from_llm(\n",
    "    retriever=vectordb.as_retriever(), llm=llm\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5a42311-ecbc-4a38-b82a-fd14e742408d",
   "metadata": {},
   "outputs": [],
   "source": [
    "meta_question = \"I will give you a multiple choice question and \\\n",
    "you will pick the right answer based on your knowledge and the given context. \\\n",
    "There will always be 5 questions, going from levels low to high. \\\n",
    "The sixth answer is always I don't know \\\n",
    "You will pick the answer from the multiple choices presented \\\n",
    "Also, after the answer, you will explain how you got to the answer, referrring to the pieces \\\n",
    "of context that gave you the answer: \\\n",
    "\\\n",
    "<question> \\\n",
    "{question} \\\n",
    "\\\n",
    "<possible answers> \\\n",
    "{answers}\\\n",
    "\"\n",
    "\n",
    "meta_prompt = PromptTemplate(\n",
    "    template = meta_question, input_variables=['question', 'answers']\n",
    ")\n",
    "\n",
    "qa_chain = RetrievalQA.from_chain_type(\n",
    "    llm,\n",
    "    retriever=retriever\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7e120ce-ab8e-4c99-b199-32207b7ed74c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper function for printing docs\n",
    "\n",
    "def pretty_print_docs(docs):\n",
    "    print(f\"\\n{'-' * 100}\\n\".join([f\"Document {i+1}:\\n\\n\" + d.page_content for i, d in enumerate(docs)]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "867d6c34-7053-4f3d-8e61-78a7836df666",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cc84bec-384f-4dc4-aa49-a39094631836",
   "metadata": {},
   "outputs": [],
   "source": [
    "question = \"To what extent is the relationship between climate hazards and \\\n",
    "social vulnerability/inequity understood among city leaders and staff?\"\n",
    "\n",
    "answers = \" \\\n",
    "1 (Low) The relationship between climate hazards and social inequity has not been explored by staff or elected officials\\\n",
    "2 (Medium) The relationship between climate hazards and social inequity is familiar to select city staff or elected \\\n",
    "officials \\\n",
    "3 (High) City staff and elected officials are well-versed in the concepts and taxonomy of the relationship between climate hazards and social inequity \\\n",
    "4 I dont know \\\n",
    "\"\n",
    "\n",
    "query = meta_prompt.format(question=question, answers=answers)\n",
    "query\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdc23a2e-98fc-4de3-807f-a87342521ced",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "result = qa_chain({\"query\": query})\n",
    "print(result[\"result\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f9d0038-87e7-4c7d-9e34-bfcf0530e4ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "question = \"Are there programs in place to support education and knowledge transfer of Equitable Climate Resilience issues?\"\n",
    "\n",
    "result = qa_chain({\"query\": question})\n",
    "print(result[\"result\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee754d48-d969-4296-b042-53c8950b1291",
   "metadata": {},
   "outputs": [],
   "source": [
    "vectordb.similarity_search(\n",
    "    question,  # our search query\n",
    "    k=5\n",
    "    # return 3 most relevant docs\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcff592e-0778-407d-9380-13d253002854",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.prompts import ChatPromptTemplate\n",
    "from langchain.schema.output_parser import StrOutputParser\n",
    "\n",
    "retriever = vectordb.as_retriever()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c02084a3-5219-461d-ad4d-3bb00ce86d34",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain import hub\n",
    "\n",
    "prompt = hub.pull('langchain-ai/rag-fusion-query-generation')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da2ae3b3-1f43-4cd9-ab3c-585102b04ad2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# prompt = ChatPromptTemplate.from_messages([\n",
    "#     (\"system\", \"You are a helpful assistant that generates multiple search queries based on a single input query.\"),\n",
    "#     (\"user\", \"Generate multiple search queries related to: {original_query}\"),\n",
    "#     (\"user\", \"OUTPUT (4 queries):\")\n",
    "# ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e823145-45fd-4725-bbdb-b75a37dbc900",
   "metadata": {},
   "outputs": [],
   "source": [
    "generate_queries = prompt | ChatOpenAI(temperature=0) | StrOutputParser() | (lambda x: x.split(\"\\n\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13f31b47-e4f6-4570-aa7d-4ec757c1e8f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.load import dumps, loads\n",
    "def reciprocal_rank_fusion(results: list[list], k=60):\n",
    "    fused_scores = {}\n",
    "    for docs in results:\n",
    "        # Assumes the docs are returned in sorted order of relevance\n",
    "        for rank, doc in enumerate(docs):\n",
    "            doc_str = dumps(doc)\n",
    "            if doc_str not in fused_scores:\n",
    "                fused_scores[doc_str] = 0\n",
    "            previous_score = fused_scores[doc_str]\n",
    "            fused_scores[doc_str] += 1 / (rank + k)\n",
    "            \n",
    "    reranked_results = [(loads(doc), score) for doc, score in sorted(fused_scores.items(), key=lambda x: x[1], reverse=True)]\n",
    "    return reranked_results "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae2f229e-0a84-4e3b-a5e4-535d122ad3f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "chain = generate_queries | retriever.map() | reciprocal_rank_fusion\n",
    "\n",
    "question = \"Are there programs in place to support education and knowledge transfer of Equitable Climate Resilience issues?\"\n",
    "\n",
    "da_context = chain.invoke({\"original_query\": query})\n",
    "\n",
    "da_context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb627955-ccdf-4df8-b82b-95fc124d4e88",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e92a9be-a0bc-4e26-8985-9fb1deeea884",
   "metadata": {},
   "outputs": [],
   "source": [
    "concatenated_content = \"\"\n",
    "for d in da_context:\n",
    "    concatenated_content += d[0].page_content + \"\\n\\n\"\n",
    "\n",
    "concatenated_content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "7d8c7c2d-9522-41bb-af34-fa7b932bf54e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Based on the given context, it is not clear how well city leaders and staff understand the relationship between climate hazards and social vulnerability/inequity. Therefore, the answer would be \"I don't know\" (option 4). The context does not provide any information about the level of understanding among city leaders and staff regarding this relationship.\n"
     ]
    }
   ],
   "source": [
    "result = qa_chain({\"query\": query, \"context\": concatenated_content})\n",
    "print(result[\"result\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a49a199e-3545-41f9-b342-8f52a2e32626",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
